{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains the role of `fit`, `transform`, and `fit_transform` within `Pipeline`.\n",
    "\n",
    "It makes data processing in the abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fitting the Pipeline ===\n",
      "[Step 1: Debug] fit_transform is called\n",
      "\n",
      "[Step 1: Debug] fit is called\n",
      "[Step 1: Debug] transform is called\n",
      "[Step 2: Debug] fit_transform is called\n",
      "\n",
      "[Step 2: Debug] fit is called\n",
      "[Step 2: Debug] transform is called\n",
      "[Step 3: Debug] fit_transform is called\n",
      "\n",
      "[Step 3: Debug] fit is called\n",
      "[Step 3: Debug] transform is called\n",
      "\n",
      "=== Transforming the Pipeline ===\n",
      "[Step 1: Debug] transform is called\n",
      "[Step 2: Debug] transform is called\n",
      "[Step 3: Debug] transform is called\n",
      "\n",
      "=== Fit-Transforming the Pipeline ===\n",
      "[Step 1: Debug] fit_transform is called\n",
      "\n",
      "[Step 1: Debug] fit is called\n",
      "[Step 1: Debug] transform is called\n",
      "[Step 2: Debug] fit_transform is called\n",
      "\n",
      "[Step 2: Debug] fit is called\n",
      "[Step 2: Debug] transform is called\n",
      "[Step 3: Debug] fit_transform is called\n",
      "\n",
      "[Step 3: Debug] fit is called\n",
      "[Step 3: Debug] transform is called\n",
      "\n",
      "=== Predicting with the Pipeline ===\n",
      "[Step 1: Debug] transform is called\n",
      "[Step 2: Debug] transform is called\n",
      "[Step 3: Debug] transform is called\n",
      "\n",
      "=== Final Predictions ===\n",
      "[1 0 2 1 2 0 1 2 2 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huijo/miniconda3/envs/torch/lib/python3.11/site-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Custom Transformer to print debug messages\n",
    "class DebugTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, name=\"\"):\n",
    "        self.name = name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print(f\"\\n[{self.name}] fit is called\")\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        print(f\"[{self.name}] transform is called\")\n",
    "        return X\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        print(f\"[{self.name}] fit_transform is called\")\n",
    "        return self.fit(X, y).transform(X)\n",
    "\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define the Pipeline\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"debug1\", DebugTransformer(name=\"Step 1: Debug\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"debug2\", DebugTransformer(name=\"Step 2: Debug\")),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"debug3\", DebugTransformer(name=\"Step 3: Debug\")),\n",
    "        (\"classifier\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print the sequence of operations during fit\n",
    "print(\"=== Fitting the Pipeline ===\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Print the sequence of operations during transform\n",
    "print(\"\\n=== Transforming the Pipeline ===\")\n",
    "# Use Pipeline[:-1] to exclude the final estimator and only apply transformations\n",
    "X_train_transformed = pipeline[:-1].transform(X_train)\n",
    "\n",
    "# Print the sequence of operations during fit_transform\n",
    "print(\"\\n=== Fit-Transforming the Pipeline ===\")\n",
    "# Use Pipeline[:-1] to exclude the final estimator and only apply transformations\n",
    "X_train_fit_transformed = pipeline[:-1].fit_transform(X_train, y_train)\n",
    "\n",
    "# Print the sequence of operations during predict\n",
    "print(\"\\n=== Predicting with the Pipeline ===\")\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Print the final predictions\n",
    "print(\"\\n=== Final Predictions ===\")\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
